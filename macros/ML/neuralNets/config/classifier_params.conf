[DNN_1]

nr_of_layers: 4
first_layer_size: 50
layers_slope_coeff: 1.0
dropout: 0.5
use_alpha_dropout: False
normalize_batch: False
noise: 0.0
activation: relu
kernel_initializer: glorot_normal
bias_initializer: zeros

[DNN_2]
nr_of_layers: 8
first_layer_size: 300
layers_slope_coeff: 1.0
dropout: 0.05
use_alpha_dropout: False
normalize_batch: True
noise: 0.0
activation: relu
kernel_initializer: glorot_normal
bias_initializer: zeros

[DNN_3]
nr_of_layers: 8
first_layer_size: 300
layers_slope_coeff: 1.0
dropout: 0.1
use_alpha_dropout: False
normalize_batch: True
noise: 0.0
activation: relu
kernel_initializer: glorot_normal
bias_initializer: zeros

[DNN_4]
nr_of_layers: 4
first_layer_size: 300
layers_slope_coeff: 1.0
dropout: 0.0
use_alpha_dropout: False
normalize_batch: True
noise: 0.0
activation: relu
kernel_initializer: glorot_normal
bias_initializer: zeros

[DNN_5]

nr_of_layers: 6
first_layer_size: 100
layers_slope_coeff: 1.0
dropout: 0.0
use_alpha_dropout: False
normalize_batch: True
noise: 0.0
activation: relu
kernel_initializer: glorot_normal
bias_initializer: zeros

[DNN_6]
nr_of_layers: 6
first_layer_size: 100
layers_slope_coeff: 1.0
dropout: 0.4
use_alpha_dropout: False
normalize_batch: True
noise: 0.0
activation: relu
kernel_initializer: glorot_normal
bias_initializer: zeros

[DNN_7]
nr_of_layers: 6
first_layer_size: 100
layers_slope_coeff: 1.0
dropout: 0.25
use_alpha_dropout: False
normalize_batch: True
noise: 0.0
activation: relu
kernel_initializer: glorot_normal
bias_initializer: zeros